{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(img_path, new_width):\n",
    "    img = cv2.imread(img_path)\n",
    "    height, width = img.shape[:2]\n",
    "    ratio = float(new_width) / width\n",
    "    new_height = int(height * ratio)\n",
    "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from plantcv import plantcv as pcv \n",
    "import warnings\n",
    "\n",
    "class options:\n",
    "    def __init__(self):\n",
    "        #self.image = '../../leafsnap/leafsnap-dataset/dataset/images/field/acer_rubrum/13001155906945.jpg'\n",
    "        # self.image = '../images/raws/acer_rubrum/13001155906945.jpg'\n",
    "        self.debug = \"none\"\n",
    "        self.writeimg= 'False' \n",
    "        self.result = \"features_metadata.json\"\n",
    "        self.outdir = \"\"\n",
    "        self.verbose= False\n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug\n",
    "pcv.params.debug = args.debug\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # img, path, filename = pcv.readimage(filename=image_path)\n",
    "    img = resizeImage(image_path, 300)\n",
    "    # Convert RGB to HSV and extract the saturation channel\n",
    "    s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n",
    "    # Threshold the saturation image\n",
    "    s_thresh = pcv.threshold.binary(gray_img=s, threshold=85, max_value=255, object_type='light')\n",
    "    # Median Blur\n",
    "    s_mblur = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "    s_cnt = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "    # Convert RGB to LAB and extract the Blue channel\n",
    "    #b = pcv.rgb2gray_lab(gray_img=img, channel='b')\n",
    "    b = pcv.rgb2gray_lab(rgb_img=img, channel='b')\n",
    "    # Threshold the blue image\n",
    "    b_thresh = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "    b_cnt = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "    # Join the thresholded saturation and blue-yellow images\n",
    "    bs = pcv.logical_or(bin_img1=s_mblur, bin_img2=b_cnt)\n",
    "    # Apply Mask (for VIS images, mask_color=white)\n",
    "    #masked = pcv.apply_mask(rgb_img=img, mask=bs, mask_color='white')\n",
    "    masked = pcv.apply_mask(img=img, mask=bs, mask_color='white')\n",
    "    # Convert RGB to LAB and extract the Green-Magenta and Blue-Yellow channels\n",
    "    masked_a = pcv.rgb2gray_lab(rgb_img=masked, channel='a')\n",
    "    masked_b = pcv.rgb2gray_lab(rgb_img=masked, channel='b')\n",
    "    # Threshold the green-magenta and blue images\n",
    "    maskeda_thresh = pcv.threshold.binary(gray_img=masked_a, threshold=115, max_value=255, object_type='dark')\n",
    "    maskeda_thresh1 = pcv.threshold.binary(gray_img=masked_a, threshold=135, max_value=255, object_type='light')\n",
    "    maskedb_thresh = pcv.threshold.binary(gray_img=masked_b, threshold=128, max_value=255, object_type='light')\n",
    "    # Join the thresholded saturation and blue-yellow images (OR)\n",
    "    ab1 = pcv.logical_or(bin_img1=maskeda_thresh, bin_img2=maskedb_thresh)\n",
    "    ab = pcv.logical_or(bin_img1=maskeda_thresh1, bin_img2=ab1)\n",
    "    # Fill small objects\n",
    "    ab_fill = pcv.fill(bin_img=ab, size=200)\n",
    "    fill_image = pcv.fill_holes(bin_img=ab)\n",
    "    # Apply mask (for VIS images, mask_color=white)\n",
    "    #masked2 = pcv.apply_mask(rgb_img=masked, mask=ab_fill, mask_color='white')\n",
    "    masked2 = pcv.apply_mask(img=masked, mask=fill_image, mask_color='white')\n",
    "    skeleton = pcv.morphology.skeletonize(mask=masked2)\n",
    "    # Identify objects\n",
    "    id_objects, obj_hierarchy = pcv.find_objects(img=img, mask=fill_image)\n",
    "\n",
    "    # get dimensions of image\n",
    "    dimensions = img.shape\n",
    "    # height, width, number of channels in image\n",
    "    # height = img.shape[0] - (img.shape[0] * (30 / 100))\n",
    "    # width = img.shape[1] - (img.shape[1] * (30 / 100))\n",
    "\n",
    "    middle_x = img.shape[1] // 2\n",
    "    middle_y = img.shape[0] // 2\n",
    "\n",
    "    # Define ROI\n",
    "    # roi1, roi_hierarchy= pcv.roi.circle(img=masked2, x=50, y=50, h=height, w=width)\n",
    "    roi1, roi_hierarchy= pcv.roi.circle(img=masked2, x=middle_x, y=middle_y, r=50)\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Decide which objects to keep\n",
    "    roi_objects, hierarchy3, kept_mask, obj_area = pcv.roi_objects(img=img, roi_contour=roi1, \n",
    "                                                                    roi_hierarchy=roi_hierarchy, \n",
    "                                                                    object_contour=id_objects, \n",
    "                                                                    obj_hierarchy=obj_hierarchy,\n",
    "                                                                    roi_type='largest')\n",
    "                                                                \n",
    "    # Object combine kept objects\n",
    "    obj, mask = pcv.object_composition(img=img, contours=roi_objects, hierarchy=hierarchy3)\n",
    "\n",
    "    # Return contours, thresh/binary, gray\n",
    "    return [roi_objects, kept_mask, img]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoCS-Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def calculate_area_measure(contour_points, radii):\n",
    "    x = []\n",
    "    y = []\n",
    "    x_y = []\n",
    "    for cp in contour_points[0]:\n",
    "        x.append(cp[0][0])\n",
    "        y.append(cp[0][1])\n",
    "        x_y.append([cp[0][0], cp[0][1]])\n",
    "\n",
    "    centroid = np.mean(x_y, axis=0)\n",
    "    abs_centroid = [int(centroid[0]), int(centroid[1])]\n",
    "    area_measures = []\n",
    "\n",
    "    for radius in radii:\n",
    "        area = 0.0\n",
    "        for cp in x_y:\n",
    "            dist = distance.euclidean(cp, abs_centroid)\n",
    "            if dist <= radius:\n",
    "                area += 1.0\n",
    "        area_measures.append(area)\n",
    "    return area_measures\n",
    "\n",
    "\n",
    "def calculate_curvature(contour_points):\n",
    "    x = []\n",
    "    y = []\n",
    "    x_y = []\n",
    "    for cp in contour_points[0]:\n",
    "        x.append(cp[0][0])\n",
    "        y.append(cp[0][1])\n",
    "        x_y.append([cp[0][0], cp[0][1]])\n",
    "\n",
    "        \n",
    "    curvatures = []\n",
    "    for i in range(len(x_y) - 2):\n",
    "        x1, y1 = x_y[i]\n",
    "        x2, y2 = x_y[i+1]\n",
    "        x3, y3 = x_y[i+2]\n",
    "        curvature = abs((x1-x2)*(y2-y3) - (x2-x3)*(y1-y2)) / ((x1-x2)**2 + (y1-y2)**2)**1.5\n",
    "        curvatures.append(curvature)\n",
    "    return curvatures\n",
    "\n",
    "\n",
    "def generate_histogram(area_measure, curvature_values, bins, range):\n",
    "    weights = np.repeat(area_measure, len(curvature_values))\n",
    "    histogram, _ = np.histogram(curvature_values, bins=bins, range=range, weights=weights)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Finished plant: acer_campestre\n",
      "Finished plant: acer_ginnala\n",
      "Finished plant: acer_pensylvanicum\n",
      "Finished plant: acer_rubrum\n",
      "Finished plant: amelanchier_canadensis\n",
      "Finished plant: asimina_triloba\n",
      "Finished plant: betula_alleghaniensis\n",
      "Finished plant: betula_nigra\n",
      "Finished plant: betula_populifolia\n",
      "Finished plant: castanea_dentata\n",
      "Finished plant: catalpa_bignonioides\n",
      "Finished plant: crataegus_pruinosa\n",
      "Finished plant: fagus_grandifolia\n",
      "Finished plant: liriodendron_tulipifera\n",
      "Finished plant: populus_deltoides\n",
      "Finished plant: populus_grandidentata\n",
      "Finished plant: quercus_bicolor\n",
      "Finished plant: quercus_nigra\n",
      "Finished plant: styrax_japonica\n",
      "Finished plant: ulmus_rubra\n",
      "Finished plant: vitex_negundo\n",
      "Finished plant: zelkova_serrata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "path = \"../compiled/\"\n",
    "counter = 0\n",
    "\n",
    "# initialize empty lists for features and labels\n",
    "hocs_list = []\n",
    "labels = []\n",
    "\n",
    "error_num = 0\n",
    "\n",
    "# loop through all subfolders in the path\n",
    "for foldername in os.listdir(path):\n",
    "    folderpath = os.path.join(path, foldername)\n",
    "    if not os.path.isdir(folderpath):\n",
    "        continue\n",
    "    # loop through all image files in the subfolder\n",
    "    for filename in os.listdir(folderpath):\n",
    "\n",
    "        # For testing to limit outputs\n",
    "        if counter == 5: break\n",
    "\n",
    "        filepath = os.path.join(folderpath, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pcv_contour = preprocess_image(filepath)\n",
    "            contours = pcv_contour[0]\n",
    "            thresh = pcv_contour[1]\n",
    "            image = pcv_contour[2]\n",
    "\n",
    "            curvatures = calculate_curvature(contours)\n",
    "            histogram, bins = np.histogram(curvatures, bins=25, range=(0.0, 1.0))\n",
    "            flattened_hist = histogram.flatten()\n",
    "\n",
    "            hocs_list.append(flattened_hist)\n",
    "            labels.append(foldername)\n",
    "\n",
    "            counter += 1\n",
    "        except:\n",
    "            error_num += 1\n",
    "            counter += 1\n",
    "            print(error_num)\n",
    "            pass\n",
    "\n",
    "    print(f\"Finished plant: {foldername}\")\n",
    "\n",
    "\n",
    "# save features and labels to a pandas dataframe and export to CSV file\n",
    "data = pd.DataFrame({\"hocs\": hocs_list})\n",
    "data[\"plant_name\"] = labels\n",
    "data.to_csv(\"../csv/HoCS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
