{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img_path):\n",
    "  plt.imshow(img_path)\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "  \n",
    "def count_pos(arr):\n",
    "  count = 0\n",
    "  for num in arr:\n",
    "    if num > 0:\n",
    "        count += 1\n",
    "\n",
    "  print(\"Number of positive elements in the array:\", count)\n",
    "\n",
    "\n",
    "def resizeImage(img_path, new_width):\n",
    "    # Load the image\n",
    "    img = cv2.imread(img_path)\n",
    "    # Get the image dimensions\n",
    "    height, width = img.shape[:2]\n",
    "    # Calculate the aspect ratio\n",
    "    ratio = float(new_width) / width\n",
    "    # Calculate the new height\n",
    "    new_height = int(height * ratio)\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height),\n",
    "                             interpolation=cv2.INTER_AREA)\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "def to_curv_image(currvature_arr, i, y):\n",
    "    # Define image size and resolution\n",
    "    img_width = 250\n",
    "    img_height = 250\n",
    "\n",
    "    # Create blank image\n",
    "    curvature_img = np.zeros((img_height, img_width), np.uint8)\n",
    "\n",
    "    # Define curvature array (example values)\n",
    "    curvature_data = currvature_arr[i][y]\n",
    "\n",
    "    # Map curvature values to pixel intensities\n",
    "    max_curvature = np.max(np.abs(curvature_data))\n",
    "    curvature_img = (np.abs(curvature_data) / max_curvature) * 255\n",
    "\n",
    "    # Apply smoothing (optional)\n",
    "\n",
    "    curvature_img = cv2.GaussianBlur(curvature_img, (5, 5), 0)\n",
    "    return curvature_img\n",
    "\n",
    "\n",
    "def to_hist(curvature_img):\n",
    "    # Define histogram parameters\n",
    "    hist_size = 21  # number of bins\n",
    "    hist_range = (0, 256)  # range of values to use for the histogram\n",
    "    curvature_img = np.uint8(curvature_img)\n",
    "    # Calculate histogram\n",
    "    histogram = cv2.calcHist([curvature_img], [0], None, [\n",
    "                             hist_size], hist_range)\n",
    "    return histogram\n",
    "\n",
    "\n",
    "def curvature(x, y, xc, yc, r):\n",
    "    # Shift coordinates to make the center of the circle the origin\n",
    "    x_shifted = x - xc\n",
    "    y_shifted = y - yc\n",
    "    # Calculate distance from each point to the center of the circle\n",
    "    d = np.sqrt(x_shifted**2 + y_shifted**2)\n",
    "    # Calculate the curvature only for points inside the circle\n",
    "    inside_circle = d <= r\n",
    "    dx_dt = np.gradient(x[inside_circle])\n",
    "    dy_dt = np.gradient(y[inside_circle])\n",
    "    d2x_dt2 = np.gradient(dx_dt)\n",
    "    d2y_dt2 = np.gradient(dy_dt)\n",
    "    denominator = dx_dt**2 + dy_dt**2\n",
    "    curvature = np.zeros_like(denominator)\n",
    "    nonzero_denominator = denominator != 0\n",
    "    curvature[nonzero_denominator] = (dx_dt[nonzero_denominator] * d2y_dt2[nonzero_denominator] -\n",
    "                                      d2x_dt2[nonzero_denominator] * dy_dt[nonzero_denominator]) / denominator[nonzero_denominator]**(3/2)\n",
    "    # Pad the curvature array with zeros for the points outside the circle\n",
    "    curvature_padded = np.zeros_like(d)\n",
    "    curvature_padded[inside_circle] = curvature\n",
    "    return curvature_padded\n",
    "\n",
    "\n",
    "def integral_curvature(x, y, xc, yc, r):\n",
    "    k = curvature(x, y, xc, yc, r)\n",
    "    return cumtrapz(k, initial=0)\n",
    "\n",
    "\n",
    "def get_integral_curvature(i, x, y, r, memo):\n",
    "    # Check if the result has already been computed\n",
    "    if (i, r) in memo:\n",
    "        return memo[(i, r)]\n",
    "    # Compute the integral curvature for a circle centered at (x[i], y[i]) with radius r\n",
    "    int_curv = integral_curvature(x, y, x[i], y[i], r)[-1]\n",
    "    # Memoize the result\n",
    "    memo[(i, r)] = int_curv\n",
    "    return abs(int_curv)\n",
    "\n",
    "\n",
    "def get_area_measure(contour, i, radius, thresh, prev_center, prev_mask):\n",
    "    # Compute current circle center and mask\n",
    "    center = (contour[i][0][0], contour[i][0][1])\n",
    "    circle_mask = np.zeros_like(gray)\n",
    "    cv2.circle(circle_mask, center, radius, (255, 255, 255), -1)\n",
    "\n",
    "    # Compute mask difference to find changed pixels\n",
    "    diff_mask = cv2.absdiff(circle_mask, prev_mask)\n",
    "    changed_pixels = np.where(diff_mask > 0)\n",
    "\n",
    "    # Compute intersection area using only changed pixels\n",
    "    intersection_mask = cv2.bitwise_and(circle_mask, thresh)\n",
    "    changed_intersection_mask = intersection_mask[changed_pixels]\n",
    "    intersection_area = np.sum(changed_intersection_mask) / 255\n",
    "\n",
    "    # Update previous center and mask\n",
    "    prev_center = center\n",
    "    prev_mask = circle_mask\n",
    "\n",
    "    # Compute area fraction\n",
    "    circle_area = np.pi * radius ** 2\n",
    "    intersection_fraction = intersection_area / circle_area\n",
    "\n",
    "    # Return area fraction\n",
    "    return intersection_fraction\n",
    "\n",
    "\n",
    "def get_curvatures(contours, radius_arr, thresh):\n",
    "    curvature_arr = []\n",
    "    # Loop over each contour\n",
    "    for contour in contours:\n",
    "        curr_1 = []\n",
    "        curr_2 = []\n",
    "\n",
    "        # Precompute the coordinates of all points in the contour\n",
    "        # x, y = contour[0][0], contour[0][1]\n",
    "        x, y = contour[:, 0, 0], contour[:, 0, 1]\n",
    "        min_x, max_x = np.min(x), np.max(x)\n",
    "        min_y, max_y = np.min(y), np.max(y)\n",
    "        mask = np.zeros_like(gray)\n",
    "        cv2.drawContours(mask, [contour], 0, (255, 255, 255), -1)\n",
    "        thresh = cv2.bitwise_and(gray, mask)\n",
    "        # Compute the area measure for each point in the contour\n",
    "        memo = {}\n",
    "        for radius in radius_arr:\n",
    "            prev_center = contour[0][0]\n",
    "            prev_mask = np.zeros_like(gray)\n",
    "            circle_perimeters = []\n",
    "            curr_area_arr = []\n",
    "            curr_int_arr = []\n",
    "            for i in range(len(contour)):\n",
    "                curr_area = [0]\n",
    "                curr_int = get_integral_curvature(i, x, y, radius, memo)\n",
    "                curr_int_arr.append(curr_int)\n",
    "                curr_area_arr.append(curr_area)\n",
    "            curr_1.append(curr_int_arr)\n",
    "            curr_2.append(curr_area_arr)\n",
    "        curvature_arr.append(curr_1)\n",
    "        curvature_arr.append(curr_2)\n",
    "\n",
    "    return curvature_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from plantcv import plantcv as pcv \n",
    "\n",
    "class options:\n",
    "    def __init__(self):\n",
    "        #self.image = '../../leafsnap/leafsnap-dataset/dataset/images/field/acer_rubrum/13001155906945.jpg'\n",
    "        # self.image = '../images/raws/acer_rubrum/13001155906945.jpg'\n",
    "        self.debug = \"none\"\n",
    "        self.writeimg= 'False' \n",
    "        self.result = \"features_metadata.json\"\n",
    "        self.outdir = \"\"\n",
    "        self.verbose= False\n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug\n",
    "pcv.params.debug = args.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # img, path, filename = pcv.readimage(filename=image_path)\n",
    "    img = resizeImage(image_path, 300)\n",
    "    # Convert RGB to HSV and extract the saturation channel\n",
    "    s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n",
    "    # Threshold the saturation image\n",
    "    s_thresh = pcv.threshold.binary(gray_img=s, threshold=85, max_value=255, object_type='light')\n",
    "    # Median Blur\n",
    "    s_mblur = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "    s_cnt = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "    # Convert RGB to LAB and extract the Blue channel\n",
    "    #b = pcv.rgb2gray_lab(gray_img=img, channel='b')\n",
    "    b = pcv.rgb2gray_lab(rgb_img=img, channel='b')\n",
    "    # Threshold the blue image\n",
    "    b_thresh = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "    b_cnt = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "    # Join the thresholded saturation and blue-yellow images\n",
    "    bs = pcv.logical_or(bin_img1=s_mblur, bin_img2=b_cnt)\n",
    "    # Apply Mask (for VIS images, mask_color=white)\n",
    "    #masked = pcv.apply_mask(rgb_img=img, mask=bs, mask_color='white')\n",
    "    masked = pcv.apply_mask(img=img, mask=bs, mask_color='white')\n",
    "    # Convert RGB to LAB and extract the Green-Magenta and Blue-Yellow channels\n",
    "    masked_a = pcv.rgb2gray_lab(rgb_img=masked, channel='a')\n",
    "    masked_b = pcv.rgb2gray_lab(rgb_img=masked, channel='b')\n",
    "    # Threshold the green-magenta and blue images\n",
    "    maskeda_thresh = pcv.threshold.binary(gray_img=masked_a, threshold=115, max_value=255, object_type='dark')\n",
    "    maskeda_thresh1 = pcv.threshold.binary(gray_img=masked_a, threshold=135, max_value=255, object_type='light')\n",
    "    maskedb_thresh = pcv.threshold.binary(gray_img=masked_b, threshold=128, max_value=255, object_type='light')\n",
    "    # Join the thresholded saturation and blue-yellow images (OR)\n",
    "    ab1 = pcv.logical_or(bin_img1=maskeda_thresh, bin_img2=maskedb_thresh)\n",
    "    ab = pcv.logical_or(bin_img1=maskeda_thresh1, bin_img2=ab1)\n",
    "    # Fill small objects\n",
    "    ab_fill = pcv.fill(bin_img=ab, size=200)\n",
    "    fill_image = pcv.fill_holes(bin_img=ab)\n",
    "    # Apply mask (for VIS images, mask_color=white)\n",
    "    #masked2 = pcv.apply_mask(rgb_img=masked, mask=ab_fill, mask_color='white')\n",
    "    masked2 = pcv.apply_mask(img=masked, mask=fill_image, mask_color='white')\n",
    "    skeleton = pcv.morphology.skeletonize(mask=masked2)\n",
    "    # Identify objects\n",
    "    id_objects, obj_hierarchy = pcv.find_objects(img=img, mask=fill_image)\n",
    "\n",
    "    # get dimensions of image\n",
    "    dimensions = img.shape\n",
    "    # height, width, number of channels in image\n",
    "    height = img.shape[0] - (img.shape[0] * (30 / 100))\n",
    "    width = img.shape[1] - (img.shape[1] * (30 / 100))\n",
    "\n",
    "    # Define ROI\n",
    "    # roi1, roi_hierarchy= pcv.roi.circle(img=masked2, x=50, y=50, h=height, w=width)\n",
    "    roi1, roi_hierarchy= pcv.roi.circle(img=masked2, x=120, y=120, r=50)\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Decide which objects to keep\n",
    "    roi_objects, hierarchy3, kept_mask, obj_area = pcv.roi_objects(img=img, roi_contour=roi1, \n",
    "                                                                    roi_hierarchy=roi_hierarchy, \n",
    "                                                                    object_contour=id_objects, \n",
    "                                                                    obj_hierarchy=obj_hierarchy,\n",
    "                                                                    roi_type='largest')\n",
    "                                                                \n",
    "    # Object combine kept objects\n",
    "    obj, mask = pcv.object_composition(img=img, contours=roi_objects, hierarchy=hierarchy3)\n",
    "\n",
    "    # Return contours, thresh/binary, gray\n",
    "    return [roi_objects, kept_mask, img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import skimage.io as io\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.segmentation as seg\n",
    "import skimage.filters as filt\n",
    "import skimage.morphology as morph\n",
    "import skimage.draw as draw\n",
    "from scipy import ndimage\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.integrate import cumtrapz\n",
    "import scipy.ndimage.filters as filters\n",
    "import time\n",
    "from scipy.spatial.distance import cdist\n",
    "import itertools\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "[ 26.  83. 124.  98.  56.  51.  55.  45.  38.  32.   3.  10.   8.   8.\n",
      "   1.   3.   3.   1.   1.   0.   0. 149. 187. 145. 113.  24.   5.   6.\n",
      "   2.   3.   7.   1.   0.   1.   0.   2.   1.   0.   0.   0.   0.   0.\n",
      " 226. 181. 129.  66.   9.   2.   1.   5.   4.   1.   1.   3.   2.   4.\n",
      "   2.   4.   1.   4.   1.   0.   0. 262. 186. 105.  48.   3.   0.   3.\n",
      "   3.   3.   4.   2.   3.   4.   4.   3.   3.   3.   3.   2.   2.   0.\n",
      " 300. 212.  68.   9.   1.   0.   5.   3.   6.   9.   6.   4.   5.   5.\n",
      "   6.   4.   0.   1.   0.   1.   1. 423. 122.  38.   0.   1.   1.   4.\n",
      "   9.   3.   2.  12.  11.   4.   6.   3.   7.   0.   0.   0.   0.   0.\n",
      " 395. 154.  26.   6.   3.   2.   2.   2.   3.   7.   4.   7.  13.   5.\n",
      "   2.   4.   2.   4.   2.   2.   1. 389. 148.  18.  10.   4.   4.   2.\n",
      "   4.   6.   6.   7.   6.  12.   5.  13.   4.   3.   1.   2.   2.   0.\n",
      " 361. 180.  11.   6.   2.   4.   3.   6.   3.   9.  16.  14.   9.   7.\n",
      "   5.   7.   3.   0.   0.   0.   0. 466.  70.   7.   6.   7.   8.   5.\n",
      "  17.  12.   7.  10.   7.   9.   5.   5.   2.   2.   0.   1.   0.   0.\n",
      " 483.  34.   8.  11.   8.  14.  12.  22.  15.   7.   8.   1.   6.   1.\n",
      "  12.   3.   1.   0.   0.   0.   0. 474.  31.  11.   7.   6.   7.  15.\n",
      "  18.  11.   9.  14.  15.   3.   7.  12.   2.   1.   1.   0.   2.   0.\n",
      " 418.  60.  11.  17.  10.  16.  10.   8.  13.  16.  10.   3.  16.   7.\n",
      "   9.   6.   8.   4.   2.   2.   0. 439.  36.   6.  15.  12.  14.  22.\n",
      "  27.  17.  14.  12.  10.   6.   9.   1.   2.   2.   2.   0.   0.   0.\n",
      " 451.  20.   5.   2.  11.  15.  28.  18.  35.  27.  18.   7.   1.   3.\n",
      "   2.   1.   2.   0.   0.   0.   0. 428.  27.   6.   2.   5.  12.  18.\n",
      "  26.  18.  20.  21.  11.   9.   7.   7.   7.   7.   9.   4.   1.   1.\n",
      " 427.  22.   1.   6.   6.   9.  11.  10.  11.  16.  29.  27.  13.  16.\n",
      "   8.  11.  17.   5.   1.   0.   0. 397.  44.   2.   5.   7.   7.  12.\n",
      "  12.  13.  24.  14.  16.  12.  24.  16.  19.   5.   9.   4.   0.   4.\n",
      " 398.  31.   3.   1.   2.   4.  11.  15.  17.  30.  22.  18.  23.  19.\n",
      "  12.  21.  18.   1.   0.   0.   0. 381.  10.   3.   1.   1.  10.  14.\n",
      "  19.  25.  30.  34.  38.  33.  16.  14.  11.   6.   0.   0.   0.   0.\n",
      " 251.  74.   4.   7.  11.  10.   5.  12.  17.  24.  56.  29.  32.  27.\n",
      "  21.  31.  17.  14.   4.   0.   0. 156.  99.  32.  22.  12.   8.   1.\n",
      "   0.   8.  20.  32.  45.  37.  26.  45.  45.  19.  18.  17.   4.   0.\n",
      " 147. 100.  44.  12.   9.   6.   6.   1.   1.   3.  32.  59.  29.  38.\n",
      "  42.  46.  26.  17.  22.   6.   0. 175.  85.  30.   4.  12.   4.   2.\n",
      "   3.   5.  14.  71.  47.  25.  29.  40.  27.  26.  19.  13.  14.   1.\n",
      " 166.  71.  24.  13.  20.   3.   9.   6.  10.  28.  63.  57.  38.  33.\n",
      "  29.  20.  25.   6.  13.  11.   1.]\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "1\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "[ 51. 132. 122. 150. 115.  84.  53.  42.  25.  15.  19.  12.  10.   8.\n",
      "   4.   3.   0.   0.   0.   0.   0. 233. 278. 178.  69.  50.  20.   4.\n",
      "   5.   3.   2.   0.   0.   2.   0.   1.   0.   0.   0.   0.   0.   0.\n",
      " 339. 252. 116.  54.  23.  15.  20.   9.   8.   3.   4.   1.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 312. 177. 106.  78.  60.  37.  21.\n",
      "  21.  14.   8.   3.   1.   4.   3.   0.   0.   0.   0.   0.   0.   0.\n",
      " 313. 194. 127.  67.  41.  29.  12.  13.  14.  12.   5.   7.   3.   2.\n",
      "   2.   3.   1.   0.   0.   0.   0. 408. 168.  90.  39.  59.  35.  19.\n",
      "  19.   4.   3.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 425. 159.  72.  56.  66.  32.  20.  12.   0.   2.   0.   1.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 260. 214.  48.  56.  39.  66.  48.\n",
      "  36.  34.  20.  19.   4.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 248. 197.  53.  62.  59.  53.  42.  39.  33.  33.  18.   7.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 125. 242.  49.  33.  48.  47.  64.\n",
      "  60.  39.  25.  31.  20.  22.  17.   9.   6.   4.   3.   1.   0.   0.\n",
      " 120. 220.  68.  31.  46.  41.  41.  41.  31.  27.  35.  34.  36.  24.\n",
      "  23.  13.  12.   2.   0.   0.   0. 175. 210.  47.  45.  37.  57.  35.\n",
      "  47.  39.  48.  63.  31.   8.   3.   0.   0.   0.   0.   0.   0.   0.\n",
      " 164. 207.  30.  31.  32.  49.  52.  77.  52.  62.  49.  21.  15.   2.\n",
      "   1.   1.   0.   0.   0.   0.   0. 191. 137.  49.  22.  40.  44.  78.\n",
      "  56.  56.  59.  33.  38.  17.  13.   9.   1.   2.   0.   0.   0.   0.\n",
      " 126. 143.  42.  41.  52.  39.  56.  55.  68.  73.  55.  45.  30.  13.\n",
      "   7.   0.   0.   0.   0.   0.   0.  52. 154.  31.  41.  39.  45.  40.\n",
      "  22.  41.  56.  69.  68.  60.  56.  29.  27.  13.   2.   0.   0.   0.\n",
      "  52. 120.  51.  48.  62.  50.  43.  74.  82.  78.  85.  46.  31.  18.\n",
      "   5.   0.   0.   0.   0.   0.   0.  21. 101.  54.  97.  64. 110. 123.\n",
      " 113.  94.  55.  12.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   2.  48.  42.  60.  93.  72.  56.  69.  77. 104.  93.  71.  41.  13.\n",
      "   3.   1.   0.   0.   0.   0.   0.   1.  24.  33.  42.  93.  84.  52.\n",
      "  41.  51.  66.  75.  92.  81.  63.  33.  14.   0.   0.   0.   0.   0.\n",
      "   0.   4.  22.  60.  81.  67.  69.  49.  60.  69.  75.  68.  84.  67.\n",
      "  43.  22.   3.   2.   0.   0.   0.   0.   3.   7.  43.  83.  87.  49.\n",
      "  23.  43.  58.  46.  65.  76.  61.  60.  54.  45.  22.  17.   3.   0.\n",
      "   0.   0.  15.  24.  94.  86.  53.  50.  37.  81.  90.  73.  62.  69.\n",
      "  35.  28.  19.  16.  10.   1.   2.   1.  12.   4.  18. 117.  69.  50.\n",
      "  73.  73.  70.  87.  57.  65.  53.  44.  20.  13.  10.   9.   0.   0.\n",
      "   2.   4.   7.  18. 150. 133.  71.  46.  62.  79.  56.  51.  37.  41.\n",
      "  40.  35.   8.   4.   1.   0.   0.]\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n"
     ]
    }
   ],
   "source": [
    "# specify path to the folder containing image files\n",
    "radius_arr = np.arange(10, 131, 5)\n",
    "# Change number to 1, 2, 3, or 4, run simultaneously \n",
    "path = \"../../leafsnap/leafsnap-dataset/dataset/images/lab_/4\"\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# initialize empty lists for features and labels\n",
    "contours_list = []\n",
    "hocs_area_list = []\n",
    "hocs_int_list = []\n",
    "labels = []\n",
    "error_num = 0\n",
    "\n",
    "# loop through all subfolders in the path\n",
    "for foldername in os.listdir(path):\n",
    "\n",
    "    folderpath = os.path.join(path, foldername)\n",
    "    if not os.path.isdir(folderpath):\n",
    "        continue\n",
    "\n",
    "    # loop through all image files in the subfolder\n",
    "    for filename in os.listdir(folderpath):\n",
    "\n",
    "        # For testing to limit outputs\n",
    "        # if counter == 2: break\n",
    "\n",
    "        filepath = os.path.join(folderpath, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # img, path, filename = pcv.readimage(filename=\"../../leafsnap/leafsnap-dataset/dataset/images/lab/acer_saccharinum/pi0066-01-1.jpg\")\n",
    "            pcv_contour = preprocess_image(filepath)\n",
    "\n",
    "            contours = np.array(pcv_contour[0])\n",
    "            thresh = pcv_contour[1]\n",
    "            image = pcv_contour[2]\n",
    "\n",
    "            # contours = pcv_contour[0]\n",
    "            # Find the contours in the image\n",
    "            # contours, hierarchy = cv2.findContours(thresh,  cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            # contours, hierarchy = cv2.findContours(thresh)\n",
    "\n",
    "            # Create a blank image for drawing contours\n",
    "            contour_image = np.zeros_like(image)\n",
    "            # Convert the contour image to grayscale\n",
    "            contour_gray = cv2.cvtColor(contour_image, cv2.COLOR_BGR2GRAY)\n",
    "            # Draw the contours on the contour image\n",
    "            cv2.drawContours(contour_image, contours, -1, (255, 255, 255), -1)\n",
    "            # Convert the contour image to grayscale\n",
    "            gray = cv2.cvtColor(contour_image, cv2.COLOR_BGR2GRAY)\n",
    "            currvature_arr = get_curvatures(contours, radius_arr, thresh)\n",
    "            # print(currvature_arr[0])\n",
    "            # print(currvature_arr[1])\n",
    "            int_hist = []\n",
    "            area_hist = []\n",
    "            for y in range(len(currvature_arr[0])):\n",
    "                curv_image_hist = to_curv_image(currvature_arr, 0, y)\n",
    "                curv_image_area = to_curv_image(currvature_arr, 1, y)\n",
    "                histogram_hist_int = to_hist(curv_image_hist)\n",
    "                histogram_hist_area = to_hist(curv_image_area)\n",
    "                int_hist.append(histogram_hist_int)\n",
    "                area_hist.append(histogram_hist_area)\n",
    "\n",
    "            flat_hist_int = np.array(int_hist).flatten()\n",
    "            flat_hist_area = np.array(area_hist).flatten()\n",
    "\n",
    "            contours_list.append(contours)\n",
    "            hocs_area_list.append(flat_hist_area)\n",
    "            hocs_int_list.append(flat_hist_int)\n",
    "            labels.append(foldername)\n",
    "            counter += 1\n",
    "\n",
    "        except:\n",
    "            error_num += 1\n",
    "            counter += 1\n",
    "            print(error_num)\n",
    "            pass\n",
    "\n",
    "    print(f\"Finished plant: {foldername}\")\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "# save features and labels to a pandas dataframe and export to CSV file\n",
    "data = pd.DataFrame({\"contours\" : contours_list,\n",
    "                    \"area_hist_values\": hocs_area_list,\n",
    "                    \"int_hist_values\": hocs_int_list})\n",
    "                    \n",
    "data[\"plant\"] = labels\n",
    "# Change number accordingly to the folder name 1, 2, 3, or 4\n",
    "data.to_csv(\"LAB_HOCS_4_INT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
