{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rxhHWBO7wRW6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,confusion_matrix, precision_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test  = 0,0,0,0\n",
        "df = None"
      ],
      "metadata": {
        "id": "-Ln7uQMtb2Nd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df):\n",
        "  df = df.dropna(inplace=True)\n",
        "\n",
        "def get_train_and_test(df):\n",
        "  # Prepare the data\n",
        "  X = df[['area','width','circularity', 'ellipticity', 'form factor','perimeter' ,'perimeter ratio of diameter', 'perimeter Ratio of Physiological Length and Physiological Width']]\n",
        "  y = df['Species']\n",
        "  # Perform Min-Max Scaling\n",
        "  min_max_scaler = MinMaxScaler()\n",
        "  X_minmax_scaled = min_max_scaler.fit_transform(X)\n",
        "\n",
        "  # Perform Standard Scaling\n",
        "  standard_scaler = StandardScaler()\n",
        "  X_standard_scaled = standard_scaler.fit_transform(X)\n",
        "  # Split the data into training and testing sets\n",
        "  global X_train, X_test, y_train, y_test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_standard_scaled, y, test_size=0.1, random_state=42)\n",
        "\n",
        "def set_optimal_perimeters():\n",
        "    # Define the hyperparameter grid for tuning\n",
        "  # Define the range and step size\n",
        "  start = 1\n",
        "  stop = 50\n",
        "  step = 0.5\n",
        "\n",
        "  # Create the array using numpy's arange function\n",
        "  arr = np.arange(start, stop + step, step)\n",
        "  gamma =  list(np.logspace(-3, 3, 20))\n",
        "  param_grid = {\n",
        "    'C':[48.2],\n",
        "    'kernel': ['rbf'],\n",
        "    'degree': [2],\n",
        "    'gamma': [6.158482110660261]\n",
        "    #['scale', 'auto'] +gamma\n",
        "  }\n",
        "  return param_grid\n",
        "\n",
        "def train(param_grid):\n",
        "  global X_train, y_train\n",
        "    # Define the SVM classifier\n",
        "  svm = SVC()\n",
        "\n",
        "  # Perform Grid Search Cross Validation\n",
        "  grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "  grid_search.fit(X_train, y_train)\n",
        "\n",
        "  # Print the best hyperparameters and corresponding accuracy\n",
        "  print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
        "  print(\"Best Accuracy: \", grid_search.best_score_)\n",
        "\n",
        "  # Train SVM with the best hyperparameters on the entire training set\n",
        "  best_svm = grid_search.best_estimator_\n",
        "  \n",
        "  best_svm.fit(X_train, y_train)\n",
        "  # Evaluate the model on the test set\n",
        "  accuracy = best_svm.score(X_test, y_test)\n",
        "  # Predict labels for test data\n",
        "  y_pred = best_svm.predict(X_test)\n",
        "\n",
        "  # Calculate confusion matrix\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  # Extract true positives, false positives, true negatives, and false negatives from confusion matrix\n",
        "\n",
        "\n",
        "  # Calculate recall\n",
        "  recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "  # Calculate precision\n",
        "  precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "\n",
        "  # Print the calculated metrics\n",
        "  print(\"Recall: {:.4f}\".format(recall))\n",
        "  print(\"Precision: {:.4f}\".format(precision))\n",
        "  print(\"Test Accuracy: \", accuracy)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "pVVCR90tbN_v"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'sheet.csv'\n",
        "df = pd.read_csv(file_path) \n",
        "preprocess(df)\n",
        "get_train_and_test(df)\n",
        "param_grid = set_optimal_perimeters()\n",
        "best_svm = train(param_grid)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jgf6AwSv2D_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ad1a9a-bb08-4b9d-c9f2-7d583b36eace"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:  {'C': 48.2, 'degree': 2, 'gamma': 6.158482110660261, 'kernel': 'rbf'}\n",
            "Best Accuracy:  0.9154970224461751\n",
            "Recall: 0.9758\n",
            "Precision: 0.9780\n",
            "Test Accuracy:  0.9757575757575757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input new data for prediction\n",
        "new_data = np.array([[ ]])  # Replace this with your new data\n",
        "\n",
        "# Make predictions\n",
        "predictions = best_svm.predict(new_data)\n",
        "\n",
        "# Print the predicted class labels\n",
        "print(\"Predicted Class Labels: \", predictions)"
      ],
      "metadata": {
        "id": "GySG0oT2WCtA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}