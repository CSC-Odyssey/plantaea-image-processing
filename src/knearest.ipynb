{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('leafsnap_data.csv')\n",
    "\n",
    "hv = [d.replace(\"'\", \"\") for d in data['hist_values']]\n",
    "hv = [ast.literal_eval(d) for d in data['hist_values']]\n",
    "\n",
    "X = hv\n",
    "y = data['plant']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Create the k-nearest neighbors model\n",
    "k = 6 # Set the value of k\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Train the model on the training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance using accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,confusion_matrix, precision_score, recall_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "def set_optimal_perimeters():\n",
    "    # Define the hyperparameter grid for tuning\n",
    "    # Define the range and step size\n",
    "    start = 1\n",
    "    stop = 100\n",
    "    step = 50\n",
    "\n",
    "    # Create the array using numpy's arange function\n",
    "    arr = np.arange(start, stop + step, step)\n",
    "    gamma = list(np.logspace(-3, 3, 30))\n",
    "    param_grid = {\n",
    "      'C':arr,\n",
    "      'kernel': ['rbf'],\n",
    "      'degree': [2],\n",
    "      'gamma': ['scale', 'auto'] + gamma\n",
    "      #['scale', 'auto'] +gamma\n",
    "    }\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'C': [101],\n",
    "    #     'kernel': ['rbf'],\n",
    "    #     'degree': [2],\n",
    "    #     'gamma': [2.976351441631316]\n",
    "    #     # ['scale', 'auto'] +gamma\n",
    "    # }\n",
    "    return param_grid\n",
    "\n",
    "\n",
    "def svm_train(param_grid, X_train, X_test, y_train, y_test):\n",
    "    # Define the SVM classifier\n",
    "    svm = SVC()\n",
    "    # Perform Grid Search Cross Validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    # Print the best hyperparameters and corresponding accuracy\n",
    "    print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "    # Train SVM with the best hyperparameters on the entire training set\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    best_svm.fit(X_train, y_train)\n",
    "    # Evaluate the model on the test set\n",
    "    accuracy = best_svm.score(X_test, y_test)\n",
    "    # Predict labels for test data\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "    return best_svm\n",
    "\n",
    "\n",
    "param_grid = set_optimal_perimeters()\n",
    "svm = svm_train(param_grid, X_train_scaled, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Accuracy:  0.7515151515151515\n",
      "Accuracy: 0.7037037037037037\n",
      "Precision: 0.7530864197530863\n",
      "Recall: 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,confusion_matrix, precision_score, recall_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "def set_optimal_perimeters():\n",
    "    # Define the hyperparameter grid for tuning\n",
    "    # Define the range and step size\n",
    "    start = 1\n",
    "    stop = 100\n",
    "    step = 50\n",
    "\n",
    "    # Create the array using numpy's arange function\n",
    "    arr = np.arange(start, stop + step, step)\n",
    "    gamma = list(np.logspace(-3, 3, 30))\n",
    "    param_grid = {\n",
    "      'C':arr,\n",
    "      'kernel': ['rbf'],\n",
    "      'degree': [2],\n",
    "      'gamma': ['scale', 'auto'] + gamma\n",
    "      #['scale', 'auto'] +gamma\n",
    "    }\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'C': [101],\n",
    "    #     'kernel': ['rbf'],\n",
    "    #     'degree': [2],\n",
    "    #     'gamma': [2.976351441631316]\n",
    "    #     # ['scale', 'auto'] +gamma\n",
    "    # }\n",
    "    return param_grid\n",
    "\n",
    "\n",
    "# Create a dataframe with the dependent and independent variables\n",
    "def print_metrics(y_test, y_pred):\n",
    "    # Evaluate the model on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    \n",
    "\n",
    "def rf_train(X_train, X_test, y_train, y_test):\n",
    "    # Define the NB classifier\n",
    "    rf = RandomForestClassifier()\n",
    "    # Define hyperparameter grid to search over\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100],  # Number of trees in the forest\n",
    "        'max_depth': [None, 10, 20],  # Maximum depth of the trees\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "        'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "        'max_features': ['sqrt', 'log2']  # Number of features to consider for the best split\n",
    "    }\n",
    "    # Create GridSearchCV object with Random Forest Classifier and hyperparameter grid\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    # Get the best hyperparameters found by GridSearchCV\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best Parameters: \", best_params)\n",
    "    print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "    # Train Random Forest Classifier with the best hyperparameters on the entire training data\n",
    "    best_rf = RandomForestClassifier(**best_params)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    # Evaluate the model on the test set\n",
    "    accuracy = best_rf.score(X_test, y_test)\n",
    "    # Predict labels for test data\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    print_metrics(y_test, y_pred)\n",
    "    return best_rf\n",
    "\n",
    "\n",
    "rf = rf_train(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
