{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.segmentation as seg\n",
    "import skimage.filters as filt\n",
    "import skimage.morphology as morph\n",
    "import skimage.draw as draw\n",
    "from scipy import ndimage\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.integrate import cumtrapz\n",
    "import scipy.ndimage.filters as filters\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plantcv import plantcv as pcv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        self.debug = \"none\"\n",
    "        self.writeimg= 'False' \n",
    "        self.result = \"features_metadata.json\"\n",
    "        self.outdir = \"\"\n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug\n",
    "pcv.params.debug = args.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantcv import plantcv as pcv\n",
    "import scipy.integrate\n",
    "\n",
    "def pcv_getContours(path):\n",
    "    # img, path, filename = pcv.readimage(filename=args.image)\n",
    "    # img, path, filename = pcv.readimage(filename=\"../../leafsnap/leafsnap-dataset/dataset/images/lab/abies_concolor/ny1157-01-1.jpg\")\n",
    "    img, path, filename = pcv.readimage(filename=path)\n",
    "\n",
    "    # Resize image using resize function, with interpolation, and default interpolation method\n",
    "    # img = pcv.transform.resize(img=img, size=(400, 300), interpolation=\"auto\")\n",
    "\n",
    "    # Convert RGB to HSV and extract the saturation channel\n",
    "    s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n",
    "    # Threshold the saturation image\n",
    "    s_thresh = pcv.threshold.binary(gray_img=s, threshold=85, max_value=255, object_type='light')\n",
    "    # Median Blur\n",
    "    s_mblur = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "    s_cnt = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "    # Convert RGB to LAB and extract the Blue channel\n",
    "    #b = pcv.rgb2gray_lab(gray_img=img, channel='b')\n",
    "    b = pcv.rgb2gray_lab(rgb_img=img, channel='b')\n",
    "    # Threshold the blue image\n",
    "    b_thresh = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "    b_cnt = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "    # Fill small objects\n",
    "    # b_fill = pcv.fill(b_thresh, 10)\n",
    "    # Join the thresholded saturation and blue-yellow images\n",
    "    bs = pcv.logical_or(bin_img1=s_mblur, bin_img2=b_cnt)\n",
    "    # Apply Mask (for VIS images, mask_color=white)\n",
    "    #masked = pcv.apply_mask(rgb_img=img, mask=bs, mask_color='white')\n",
    "    masked = pcv.apply_mask(img=img, mask=bs, mask_color='white')\n",
    "    # Convert RGB to LAB and extract the Green-Magenta and Blue-Yellow channels\n",
    "    masked_a = pcv.rgb2gray_lab(rgb_img=masked, channel='a')\n",
    "    masked_b = pcv.rgb2gray_lab(rgb_img=masked, channel='b')\n",
    "    # Threshold the green-magenta and blue images\n",
    "    maskeda_thresh = pcv.threshold.binary(gray_img=masked_a, threshold=115, max_value=255, object_type='dark')\n",
    "    maskeda_thresh1 = pcv.threshold.binary(gray_img=masked_a, threshold=135, max_value=255, object_type='light')\n",
    "    maskedb_thresh = pcv.threshold.binary(gray_img=masked_b, threshold=128, max_value=255, object_type='light')\n",
    "    # Join the thresholded saturation and blue-yellow images (OR)\n",
    "    ab1 = pcv.logical_or(bin_img1=maskeda_thresh, bin_img2=maskedb_thresh)\n",
    "    ab = pcv.logical_or(bin_img1=maskeda_thresh1, bin_img2=ab1)\n",
    "    # Fill small objects\n",
    "    ab_fill = pcv.fill(bin_img=ab, size=200)\n",
    "    # Apply mask (for VIS images, mask_color=white)\n",
    "    #masked2 = pcv.apply_mask(rgb_img=masked, mask=ab_fill, mask_color='white')\n",
    "    masked2 = pcv.apply_mask(img=masked, mask=ab_fill, mask_color='white')\n",
    "    skeleton = pcv.morphology.skeletonize(mask=masked2)\n",
    "    # Identify objects\n",
    "    id_objects, obj_hierarchy = pcv.find_objects(img=img, mask=ab_fill)\n",
    "    dimensions = img.shape\n",
    "    # height, width, number of channels in image\n",
    "    height = img.shape[0] - (img.shape[0] * (30 / 100))\n",
    "    width = img.shape[1] - (img.shape[1] * (30 / 100))\n",
    "    # Define ROI\n",
    "    roi1, roi_hierarchy= pcv.roi.rectangle(img=masked2, x=100, y=100, h=height, w=width)\n",
    "    # # Auto-define the ROI using the \"auto_roi\" function\n",
    "    # roi1, roi_heirarchy = pcv.auto_roi(masked2)\n",
    "    # Decide which objects to keep\n",
    "    roi_objects, hierarchy3, kept_mask, obj_area = pcv.roi_objects(img=img, roi_contour=roi1, \n",
    "                                                                   roi_hierarchy=roi_hierarchy, \n",
    "                                                                   object_contour=id_objects, \n",
    "                                                                   obj_hierarchy=obj_hierarchy,\n",
    "                                                                   roi_type='partial')\n",
    "    # Object combine kept objects\n",
    "    global thresh\n",
    "    obj, thresh = pcv.object_composition(img=img, contours=roi_objects, hierarchy=hierarchy3)\n",
    "    return obj\n",
    "\n",
    "    \n",
    "def curvature(x, y, xc, yc, r):\n",
    "    # Shift coordinates to make the center of the circle the origin\n",
    "    x_shifted = x - xc\n",
    "    y_shifted = y - yc\n",
    "    # Calculate distance from each point to the center of the circle\n",
    "    d = np.sqrt(x_shifted**2 + y_shifted**2)\n",
    "    # Calculate the curvature only for points inside the circle\n",
    "    inside_circle = d <= r\n",
    "    dx_dt = np.gradient(x[inside_circle])\n",
    "    dy_dt = np.gradient(y[inside_circle])\n",
    "    d2x_dt2 = np.gradient(dx_dt)\n",
    "    d2y_dt2 = np.gradient(dy_dt)\n",
    "    curvature = (dx_dt * d2y_dt2 - d2x_dt2 * dy_dt) / (dx_dt**2 + dy_dt**2)**(3/2)\n",
    "    # Pad the curvature array with zeros for the points outside the circle\n",
    "    curvature_padded = np.zeros_like(d)\n",
    "    curvature_padded[inside_circle] = curvature\n",
    "    return curvature_padded\n",
    "\n",
    "\n",
    "def integral_curvature(x, y, xc, yc, r):\n",
    "    k = curvature(x, y, xc, yc, r)\n",
    "    return cumtrapz(k, initial=0)\n",
    "\n",
    "\n",
    "def get_integral_curvature(i,x,y, r):\n",
    "    # Calculate the integral curvature for a circle centered at (x[i], y[i]) with radius r\n",
    "    int_curv = integral_curvature(x, y, x[i], y[i], r)[-1]\n",
    "    return int_curv\n",
    "\n",
    "\n",
    "def get_area_measure(contour,i,radius, thresh):\n",
    "    # Approximate the contour with a circle centered at the current point\n",
    "    circle_mask = np.zeros_like(s)\n",
    "    cv2.circle(circle_mask, (contour[i][0][0], contour[i][0][1]), radius, (255, 255, 255), -1)\n",
    "    intersection_mask = cv2.bitwise_and(circle_mask, thresh)\n",
    "    intersection_area = np.sum(intersection_mask) / 255\n",
    "    circle_area = np.pi * radius ** 2\n",
    "    intersection_fraction = intersection_area / circle_area\n",
    "    # Compute the curvature value for the current point\n",
    "    return intersection_fraction\n",
    "\n",
    "\n",
    "def get_curvature_arc_length(contour,i,x,y,radius,circle_perimeters):\n",
    "    curvature_arr = []\n",
    "    # Approximate the contour with a circle centered at the current point\n",
    "    (cx, cy) = x[i], y[i]\n",
    "    # Calculate the length of the part of the circle's circumference that is inside the object\n",
    "    chord_length = 2 * np.sqrt(radius**2 - ((radius**2-(x[i]-cx)**2-(y[i]-cy)**2))/4)\n",
    "    arc_length = 2 * np.arcsin(chord_length / (2 * radius))\n",
    "    circle_perimeters.append(arc_length)\n",
    "    if len(circle_perimeters) > 0:\n",
    "        # Calculate the average perimeter of the fitted circles\n",
    "        circle_perimeter = np.mean(circle_perimeters)\n",
    "    else:\n",
    "        # Use the radius as an estimate for the perimeter\n",
    "        circle_perimeter = 2 * np.pi * radius\n",
    "\n",
    "    # Calculate perimeter of the contour\n",
    "    contour_perimeter = cv2.arcLength(contour, True)\n",
    "    # Calculate the fraction of the circle's perimeter contained inside the object\n",
    "    fraction = circle_perimeter / contour_perimeter\n",
    "    arc_len = fraction * arc_length\n",
    "    return arc_len\n",
    "\n",
    "\n",
    "def get_curvatures(contours, radius_arr, thresh):\n",
    "    curvature_arr=[]\n",
    "    # contours = np.array([contours])\n",
    "    # Loop over each contour\n",
    "    for contour in contours:\n",
    "        curr = []\n",
    "        # Precompute the coordinates of all points in the contour\n",
    "        x, y = contour[:, 0, 0], contour[:, 0, 1]\n",
    "        # Compute the maximum and minimum x and y coordinates of the contour\n",
    "        min_x, max_x = np.min(x), np.max(x)\n",
    "        min_y, max_y = np.min(y), np.max(y)\n",
    "        # Compute the thresholded image for the current contour\n",
    "        mask = np.zeros_like(s)\n",
    "        cv2.drawContours(mask, [contour], 0, (255, 255, 255), -1)\n",
    "        thresh = cv2.bitwise_and(s, mask)\n",
    "        # Compute the area measure for each point in the contour\n",
    "\n",
    "        for radius in radius_arr:\n",
    "            circle_perimeters = []\n",
    "            arc_length = 0  # Initialize arc_length to 0\n",
    "            curr = []\n",
    "            for i in range(len(contour)):\n",
    "                curr_area = get_area_measure(contour,i,radius,thresh)\n",
    "                # curr_arc = get_curvature_arc_length(contour,i,x,y,radius,circle_perimeters)\n",
    "                # curr_int = get_integral_curvature(i,x,y, radius)\n",
    "                curr.append(curr_area) # remove\n",
    "                #curr.append(curr_arc)\n",
    "                #curr.append(curr_int) # add\n",
    "            curvature_arr.append(curr)\n",
    "    return curvature_arr\n",
    "            #print( f'area={curr_area} arc ={curr_arc} curr int = {curr_int}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(img_path, new_width):\n",
    "    # Load the image\n",
    "    img = cv2.imread(img_path)\n",
    "    # Get the image dimensions\n",
    "    height, width = img.shape[:2]\n",
    "    # Calculate the aspect ratio\n",
    "    ratio = float(new_width) / width\n",
    "    # Calculate the new height\n",
    "    new_height = int(height * ratio)\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute curvature value given three points\n",
    "def compute_curvature(p1, p2, p3):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "\n",
    "    # Compute distance between points\n",
    "    d12 = math.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "    d23 = math.sqrt((x3-x2)**2 + (y3-y2)**2)\n",
    "    d13 = math.sqrt((x3-x1)**2 + (y3-y1)**2)\n",
    "\n",
    "    # Compute curvature\n",
    "    if d12 == 0 or d23 == 0 or d13 == 0:\n",
    "        curvature = 0\n",
    "    else:\n",
    "        s = (d12 + d23 + d13) / 2\n",
    "        area = math.sqrt(s * (s - d12) * (s - d23) * (s - d13))\n",
    "        radius = (d12 * d23 * d13) / (4 * area)\n",
    "        curvature = 1 / radius\n",
    "\n",
    "    return curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24496\\625469338.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[1;31m# Search for appropriate points in both directions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mleft_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                     \u001b[0mright_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                     \u001b[1;31m# Combine the appropriate points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24496\\625469338.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[1;31m# Search for appropriate points in both directions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mleft_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                     \u001b[0mright_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                     \u001b[1;31m# Combine the appropriate points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# # Convert RGB to HSV and extract the saturation channel\n",
    "# s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n",
    "# # Threshold the saturation image\n",
    "# s_thresh = pcv.threshold.binary(gray_img=s, threshold=85, max_value=255, object_type='light')\n",
    "\n",
    "\n",
    "# specify path to the folder containing image files\n",
    "path = \"../../leafsnap/leafsnap-dataset/dataset/images/lab_/1\"\n",
    "counter = 0\n",
    "\n",
    "# initialize empty lists for features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# loop through all subfolders in the path\n",
    "for foldername in os.listdir(path):\n",
    "    if counter == 2:\n",
    "        break\n",
    "    \n",
    "    folderpath = os.path.join(path, foldername)\n",
    "    if not os.path.isdir(folderpath):\n",
    "        continue\n",
    "    \n",
    "    # loop through all image files in the subfolder\n",
    "    for filename in os.listdir(folderpath):\n",
    "        filepath = os.path.join(folderpath, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            continue\n",
    "\n",
    "        # img, path, filename = pcv.readimage(filename=\"../../leafsnap/leafsnap-dataset/dataset/images/lab/abies_concolor/ny1157-01-1.jpg\")\n",
    "        img = resizeImage(filepath, 300)\n",
    "        # Resize image using resize function, with interpolation, and default interpolation method\n",
    "        # img = pcv.transform.resize(img=img, size=(400, 300), interpolation=\"auto\")\n",
    "        # Convert RGB to HSV and extract the saturation channel\n",
    "        s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n",
    "        # Threshold the saturation image\n",
    "        s_thresh = pcv.threshold.binary(gray_img=s, threshold=85, max_value=255, object_type='light')\n",
    "        # Median Blur\n",
    "        s_mblur = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "        s_cnt = pcv.median_blur(gray_img=s_thresh, ksize=5)\n",
    "        # Convert RGB to LAB and extract the Blue channel\n",
    "        #b = pcv.rgb2gray_lab(gray_img=img, channel='b')\n",
    "        b = pcv.rgb2gray_lab(rgb_img=img, channel='b')\n",
    "        # Threshold the blue image\n",
    "        b_thresh = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "        b_cnt = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, object_type='light')\n",
    "        # Fill small objects\n",
    "        # b_fill = pcv.fill(b_thresh, 10)\n",
    "        # Join the thresholded saturation and blue-yellow images\n",
    "        bs = pcv.logical_or(bin_img1=s_mblur, bin_img2=b_cnt)\n",
    "        # Apply Mask (for VIS images, mask_color=white)\n",
    "        #masked = pcv.apply_mask(rgb_img=img, mask=bs, mask_color='white')\n",
    "        masked = pcv.apply_mask(img=img, mask=bs, mask_color='white')\n",
    "        # Convert RGB to LAB and extract the Green-Magenta and Blue-Yellow channels\n",
    "        masked_a = pcv.rgb2gray_lab(rgb_img=masked, channel='a')\n",
    "        masked_b = pcv.rgb2gray_lab(rgb_img=masked, channel='b')\n",
    "        # Threshold the green-magenta and blue images\n",
    "        maskeda_thresh = pcv.threshold.binary(gray_img=masked_a, threshold=115, max_value=255, object_type='dark')\n",
    "        maskeda_thresh1 = pcv.threshold.binary(gray_img=masked_a, threshold=135, max_value=255, object_type='light')\n",
    "        maskedb_thresh = pcv.threshold.binary(gray_img=masked_b, threshold=128, max_value=255, object_type='light')\n",
    "        # Join the thresholded saturation and blue-yellow images (OR)\n",
    "        ab1 = pcv.logical_or(bin_img1=maskeda_thresh, bin_img2=maskedb_thresh)\n",
    "        ab = pcv.logical_or(bin_img1=maskeda_thresh1, bin_img2=ab1)\n",
    "        # Fill small objects\n",
    "        ab_fill = pcv.fill(bin_img=ab, size=200)\n",
    "        # Apply mask (for VIS images, mask_color=white)\n",
    "        #masked2 = pcv.apply_mask(rgb_img=masked, mask=ab_fill, mask_color='white')\n",
    "        masked2 = pcv.apply_mask(img=masked, mask=ab_fill, mask_color='white')\n",
    "        skeleton = pcv.morphology.skeletonize(mask=masked2)\n",
    "        # Identify objects\n",
    "        id_objects, obj_hierarchy = pcv.find_objects(img=ab_fill, mask=ab_fill)\n",
    "        dimensions = img.shape\n",
    "        # height, width, number of channels in image\n",
    "        height = img.shape[0] - (img.shape[0] * (30 / 100))\n",
    "        width = img.shape[1] - (img.shape[1] * (30 / 100))\n",
    "        # Define ROI\n",
    "        roi1, roi_hierarchy= pcv.roi.rectangle(img=masked2, x=50, y=50, h=height, w=width)\n",
    "        # # Auto-define the ROI using the \"auto_roi\" function\n",
    "        # roi1, roi_heirarchy = pcv.auto_roi(masked2)\n",
    "        # Decide which objects to keep\n",
    "        roi_objects, hierarchy3, kept_mask, obj_area = pcv.roi_objects(img=img, roi_contour=roi1, \n",
    "                                                                       roi_hierarchy=roi_hierarchy, \n",
    "                                                                       object_contour=id_objects, \n",
    "                                                                       obj_hierarchy=obj_hierarchy,\n",
    "                                                                       roi_type='partial')\n",
    "        obj, thresh = pcv.object_composition(img=img, contours=roi_objects, hierarchy=hierarchy3)\n",
    "\n",
    "\n",
    "        # Define the scales and radii to use\n",
    "        n_scales = 25\n",
    "        scales = np.linspace(0.1, 1.0, n_scales)\n",
    "        radii = np.around(scales * np.mean(thresh.shape) / 2).astype(int)\n",
    "\n",
    "        # Define the number of bins to use\n",
    "        n_bins = 21\n",
    "\n",
    "        # Initialize the histograms\n",
    "        HoCS = np.zeros((n_scales, n_bins))\n",
    "\n",
    "        # Loop over the contours\n",
    "        for i, contour in enumerate(obj):\n",
    "            # Loop over the scales\n",
    "            for j, r in enumerate(radii):\n",
    "                # Initialize the curvature values list\n",
    "                curvatures = np.zeros(len(contour))\n",
    "\n",
    "                # Loop over the contour points\n",
    "                for k, point in enumerate(contour):\n",
    "                    # Define the center of the disk\n",
    "                    center = tuple(point)\n",
    "\n",
    "                    # Define the start and end points for searching along the contour\n",
    "                    start = max(0, j - r)\n",
    "                    end = j + r + 1\n",
    "\n",
    "                    # Search for appropriate points in both directions\n",
    "                    left_points = [contour[m] for m in range(start, j)]\n",
    "                    right_points = [contour[m] for m in range(j, end)]\n",
    "\n",
    "                    # Combine the appropriate points\n",
    "                    points = right_points + left_points\n",
    "\n",
    "                    # If there are not enough points, skip to the next iteration\n",
    "                    if len(points) < 2*r:\n",
    "                        continue\n",
    "                    \n",
    "                    # Convert the points to a numpy array\n",
    "                    points = np.array(points)\n",
    "\n",
    "                    # Translate the points so that the center is at the origin\n",
    "                    points = points - center\n",
    "\n",
    "                    # Compute the curvature values for each scale\n",
    "                    for s, radius in enumerate(radii):\n",
    "                        # Compute the offset coordinates for the current scale\n",
    "                        offsets = offset_dict[radius]\n",
    "\n",
    "                        # Compute the curvature values\n",
    "                        curvature_values = []\n",
    "                        for offset in offsets:\n",
    "                            next_point = points[offset] if offset < len(points) else points[offset-len(points)]\n",
    "                            prev_point = points[offset-1]\n",
    "                            curvature_values.append(curvature(prev_point, next_point))\n",
    "\n",
    "                        # Compute the mean curvature value for the current scale\n",
    "                        curvatures[s, j] = np.mean(curvature_values)\n",
    "\n",
    "            # Compute the histograms of curvature values at each scale\n",
    "            histograms = []\n",
    "            for s in range(n_scales):\n",
    "                hist, bin_edges = np.histogram(curvatures[s], bins=bins, range=(-1, 1))\n",
    "                histograms.append(hist)\n",
    "\n",
    "            # Concatenate the histograms to form the HoCS descriptor for the current contour\n",
    "            descriptor = np.concatenate(histograms)\n",
    "            HoCS[i] = descriptor\n",
    "            \n",
    "\n",
    "# # convert features and labels to numpy arrays\n",
    "# features = features\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# # save features and labels to a pandas dataframe and export to CSV file\n",
    "# data = pd.DataFrame({\"hist_values\" : features})\n",
    "# data[\"plant\"] = labels\n",
    "# data.to_csv(\"leafsnap_data_fin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'bitwise_and'\n> Overload resolution failed:\n>  - src1 is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24496\\1408285014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mradius_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m170\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m190\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m210\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m220\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m230\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mini_curvature_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_curvatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mcurvature_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mini_curvature_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurvature_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# x-axis is the number of contour points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24496\\653438728.py\u001b[0m in \u001b[0;36mget_curvatures\u001b[1;34m(contours, radius_arr, thresh)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;31m# Compute the area measure for each point in the contour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'bitwise_and'\n> Overload resolution failed:\n>  - src1 is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n"
     ]
    }
   ],
   "source": [
    "# # Convert RGB to HSV and extract the saturation channel\n",
    "# s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n",
    "# # Threshold the saturation image\n",
    "# s_thresh = pcv.threshold.binary(gray_img=s, threshold=85, max_value=255, object_type='light')\n",
    "\n",
    "\n",
    "# specify path to the folder containing image files\n",
    "path = \"../../leafsnap/leafsnap-dataset/dataset/segmented/lab_/1\"\n",
    "s = []\n",
    "counter = 0\n",
    "\n",
    "# initialize empty lists for features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# loop through all subfolders in the path\n",
    "for foldername in os.listdir(path):\n",
    "    if counter == 2:\n",
    "        break\n",
    "    \n",
    "    folderpath = os.path.join(path, foldername)\n",
    "    if not os.path.isdir(folderpath):\n",
    "        continue\n",
    "    \n",
    "    # loop through all image files in the subfolder\n",
    "    for filename in os.listdir(folderpath):\n",
    "        filepath = os.path.join(folderpath, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            continue\n",
    "        # try:\n",
    "        # load the image file and extract features\n",
    "        img = cv2.imread(filepath)\n",
    "\n",
    "        # resize the image\n",
    "        # img = cv2.resize(ini_img, (250, 250))\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # test = pcv.threshold.binary(gray_img=gray, threshold=85, max_value=255, object_type='dark')\n",
    "        # Threshold the image to get a binary image\n",
    "        ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "        # Find the contours in the image\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        radius_arr = [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250]\n",
    "        ini_curvature_arr = get_curvatures(contours, radius_arr, thresh)\n",
    "        curvature_arr = np.array(ini_curvature_arr)\n",
    "        x = np.arange(curvature_arr.shape[1]) # x-axis is the number of contour points\n",
    "        y = np.arange(curvature_arr.shape[0]) # y-axis is the different scales\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        \n",
    "        hist_values = []\n",
    "        for i in range(curvature_arr.shape[0]):\n",
    "            counts, bin_edges = np.histogram(curvature_arr[i], bins=21) # adjust the number of bins as needed\n",
    "            hist_values.append(counts)\n",
    "        data = np.array([np.array(hist) for hist in hist_values])\n",
    "        X = data.flatten().tolist()\n",
    "        print(X)\n",
    "        features.append(X)\n",
    "        labels.append(foldername)\n",
    "        # except:\n",
    "        #    pass\n",
    "        \n",
    "    print(f\"Finished plant: {foldername}\")\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "# convert features and labels to numpy arrays\n",
    "features = features\n",
    "labels = np.array(labels)\n",
    "\n",
    "# save features and labels to a pandas dataframe and export to CSV file\n",
    "data = pd.DataFrame({\"hist_values\" : features})\n",
    "data[\"plant\"] = labels\n",
    "data.to_csv(\"leafsnap_data_fin_seg.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Plant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
