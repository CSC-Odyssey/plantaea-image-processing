{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTS**"
      ],
      "metadata": {
        "id": "o0mLaISr7xAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "Zy9D3IGWcVdS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = None\n",
        "texture = None\n",
        "file_path = 'features_data - Sheet1.csv'"
      ],
      "metadata": {
        "id": "zHfMSzynGsID"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FUNCTIONS FOR PROCESSING IMAGE**"
      ],
      "metadata": {
        "id": "uRZmaPrgSxtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show(img_path):\n",
        "  plt.imshow(img_path)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def resizeImage(image):\n",
        "  try:\n",
        "    # Get the dimensions of the original image\n",
        "    original_height, original_width, _ = image.shape\n",
        "\n",
        "    # Specify the desired dimensions of the resized image\n",
        "    desired_width = 300\n",
        "    desired_height = 400\n",
        "\n",
        "    # Calculate the aspect ratio of the original image\n",
        "    aspect_ratio = original_width / original_height\n",
        "\n",
        "    # Apply the aspect ratio to the desired dimensions\n",
        "    if desired_width / aspect_ratio <= desired_height:\n",
        "        # Use the desired width to calculate the height\n",
        "        new_width = desired_width\n",
        "        new_height = int(new_width / aspect_ratio)\n",
        "    else:\n",
        "        # Use the desired height to calculate the width\n",
        "        new_height = desired_height\n",
        "        new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "    # Resize the image\n",
        "    resized_image = cv2.resize(image, (new_width, new_height))\n",
        "    return resized_image\n",
        "  except Exception as e:\n",
        "    print(\"Error in resizing image\", e)\n",
        "    return image\n",
        "def getDiameter(contour, circularity, rectangularity, ellipticity,area ):\n",
        "  try:\n",
        "    # Fit an ellipse to the largest contour\n",
        "    if ellipticity > circularity and rectangularity:\n",
        "      ellipse = cv2.fitEllipse(contour)\n",
        "\n",
        "    # Extract the major and minor axes of the ellipse\n",
        "      major_axis = max(ellipse[1])\n",
        "      minor_axis = min(ellipse[1])\n",
        "\n",
        "    # Calculate the diameter as the maximum of major and minor axes\n",
        "      diameter = max(major_axis, minor_axis)\n",
        "      \n",
        "    elif circularity > ellipticity and rectangularity:\n",
        "      diameter = 2 * np.sqrt((area * circularity**2) / np.pi)\n",
        "    else:\n",
        "      diameter = np.sqrt(area / rectangularity)\n",
        "    return diameter\n",
        "  except Exception as e:\n",
        "    print(\"Error in getting the diameter\", e)\n",
        "    return 0  \n",
        "\n",
        "def getTexture(image):\n",
        "  try:\n",
        "    image = np.array(image, np.uint8)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    huMomentsList = []\n",
        "    for contour in contours:\n",
        "        moments = cv2.moments(contour)\n",
        "        huMoments = cv2.HuMoments(moments)\n",
        "        huMomentsList.append(huMoments)\n",
        "    huMomentsList = np.array(huMomentsList)\n",
        "    mean = np.mean(huMomentsList, axis=0)\n",
        "    std_dev = np.std(huMomentsList, axis=0)\n",
        "    for i in range(7):\n",
        "      mean[i] = -np.sign(mean[i]) * np.log10(abs(mean[i]))\n",
        "      std_dev[i] = -np.sign(std_dev[i]) * np.log10(abs(std_dev[i]))\n",
        "\n",
        "    reference_values = {\n",
        "      'Class 1': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
        "      'Class 2': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
        "      'Class 3': [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
        "      'Class 4': [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4],\n",
        "      'Class 5': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
        "      'Class 6': [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6],\n",
        "      'Class 7': [0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7],\n",
        "      'Class 8': [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],\n",
        "      'Class 9': [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
        "\n",
        "    }\n",
        "    distances = {}\n",
        "    for key in reference_values:\n",
        "      ref = np.array(reference_values[key])\n",
        "      dist = np.sqrt(np.sum((mean - ref) ** 2))\n",
        "      distances[key] = dist\n",
        "    classification = min(distances, key=distances.get)\n",
        "    if classification == 'Class 1':\n",
        "      return 1\n",
        "    elif classification == 'Class 2':\n",
        "      return 2\n",
        "    elif classification == 'Class 3':\n",
        "      return 3\n",
        "    elif classification == 'Class 4':\n",
        "      return 4\n",
        "    elif classification == 'Class 5':\n",
        "      return 5\n",
        "    elif classification == 'Class 6':\n",
        "      return 6\n",
        "    elif classification == 'Class 7':\n",
        "      return 7\n",
        "    elif classification == 'Class 8':\n",
        "      return 8\n",
        "    elif classification == 'Class 9':\n",
        "      return 9\n",
        "  except Exception as e:\n",
        "    print(\"Error in getting Texture of the image\", e)\n",
        "    return None\n",
        "def applyFilters(image):\n",
        "  \n",
        "  try:\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    ksize = (3, 3)  # kernel size\n",
        "    sigmaX = 3  # standard deviation in X direction\n",
        "    blur = cv2.GaussianBlur(image, ksize, sigmaX)\n",
        "\n",
        "    # Apply Median blur to reduce noise\n",
        "    ksize = 5  # kernel size (must be odd)\n",
        "    median = cv2.medianBlur(blur, ksize)\n",
        "\n",
        "    # Apply Bilateral filter to reduce noise\n",
        "    d = 1  # diameter of each pixel neighborhood\n",
        "    sigmaColor = 100  # filter sigma in the color space\n",
        "    sigmaSpace = 100  # filter sigma in the coordinate space\n",
        "    bilateral = cv2.bilateralFilter(median, d, sigmaColor, sigmaSpace)\n",
        "\n",
        "    return bilateral\n",
        "  except Exception as e:\n",
        "    print(\"Error in applying Filters image\", e)\n",
        "    return image\n",
        "def flatten(filtered_image):\n",
        "  try:\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(filtered_image, cv2.COLOR_BGR2GRAY)\n",
        "    # Perform adaptive histogram equalization to normalize the image\n",
        "    # You can adjust the clipLimit and tileGridSize parameters to control the normalization effect\n",
        "    clahe = cv2.createCLAHE(clipLimit=0.5, tileGridSize=(8, 8))\n",
        "    normalized_image = clahe.apply(gray_image)\n",
        "\n",
        "    # Convert the normalized image back to BGR color space\n",
        "    normalized_image = cv2.cvtColor(normalized_image, cv2.COLOR_GRAY2BGR)\n",
        "    # Resize the mask to match the size of the input image\n",
        "    mask = cv2.threshold(gray_image, 25, 255, cv2.THRESH_BINARY)[1]\n",
        "    mask = cv2.resize(mask, (filtered_image.shape[1], filtered_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Perform bitwise_and operation on the image and mask\n",
        "    output_image = cv2.bitwise_and(filtered_image, filtered_image, mask=mask)\n",
        "\n",
        "    # Perform bitwise_not operation on the mask\n",
        "    not_mask = cv2.bitwise_not(mask)\n",
        "    not_mask = cv2.resize(not_mask, (normalized_image.shape[1], normalized_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    normalized_not_mask = cv2.bitwise_and(normalized_image, normalized_image, mask=not_mask)\n",
        "\n",
        "    # Add the bitwise_and results to get the final output image\n",
        "    output_image = cv2.add(output_image, normalized_not_mask)\n",
        "\n",
        "    return output_image\n",
        "  except Exception as e:\n",
        "    print(\"Error in flattening image\", e)\n",
        "    return filtered_image\n",
        "def remove_background(flattened_image):\n",
        "  try:\n",
        "    mask = np.zeros(flattened_image.shape[:2], np.uint8)\n",
        "    rect = (10, 10, flattened_image.shape[1]-20, flattened_image.shape[0]-20)\n",
        "    cv2.grabCut(flattened_image, mask, rect, None, None, 5, cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "    # Create a binary mask from the grabcut mask\n",
        "    binary_mask = np.where((mask == 2) | (mask == 0), 0, 1).astype(np.uint8)\n",
        "\n",
        "    # Apply the binary mask to the original image\n",
        "    flattened_image = cv2.bitwise_and(flattened_image, flattened_image, mask=binary_mask)\n",
        "\n",
        "\n",
        "    return flattened_image\n",
        "  except Exception as e:\n",
        "    print(\"Error in removing background\", e)\n",
        "    return flattened_image\n",
        "\n",
        "def get_edge(image):\n",
        "  try:\n",
        "    # Apply Scharr operator for x and y directions\n",
        "    scharr_x = cv2.Scharr(image, cv2.CV_64F, 1, 0)\n",
        "    scharr_y = cv2.Scharr(image, cv2.CV_64F, 0, 1)\n",
        "\n",
        "    # Compute the gradient magnitude and direction\n",
        "    grad_mag = cv2.magnitude(scharr_x, scharr_y)\n",
        "    grad_dir = cv2.phase(scharr_x, scharr_y, angleInDegrees=True)\n",
        "\n",
        "    threshold_value = 200  # Adjust this threshold value as needed\n",
        "    _, edges = cv2.threshold(grad_mag, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "    edges = edges.astype(np.uint8)\n",
        "    return edges\n",
        "  except Exception as e:\n",
        "    print(\"Error in getting edge\", e)\n",
        "    return image\n",
        "\n",
        "def get_contours(edges,image):\n",
        "  try:\n",
        "    edge = cv2.Canny(edges, 50, 100)\n",
        "\n",
        "\n",
        "    # Perform dilation on the edges\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    dilated_edges = cv2.dilate(edge, kernel, iterations=1)\n",
        "\n",
        "    # Perform erosion on the edges\n",
        "    eroded_edges = cv2.erode(edge, kernel, iterations=3)\n",
        "    # Find contours in the binary image\n",
        "    contours, hierarchy = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt =max(contours, key=cv2.contourArea)\n",
        "    cv2.drawContours(image, [cnt], 0, (255, 0, 0), 3)  # green color, line thickness = 3\n",
        "    global texture\n",
        "    texture = getTexture(image)\n",
        "    return cnt\n",
        "  except Exception as e:\n",
        "    print(\"Error in getting contours\", e)\n",
        "    return None\n",
        "def get_features(cnt):\n",
        "  try:\n",
        "    moments = cv2.moments(cnt)\n",
        "      \n",
        "    # Calculate circularity\n",
        "    perimeter = cv2.arcLength(cnt, True)\n",
        "    area = cv2.contourArea(cnt)\n",
        "    circularity = 4 * np.pi * area / (perimeter ** 2)\n",
        "        \n",
        "    # Calculate rectangularity\n",
        "    x,y,w,h = cv2.boundingRect(cnt)\n",
        "    rectangularity = w/h\n",
        "        \n",
        "    # Calculate ellipticity\n",
        "    a = moments['mu20'] + moments['mu02']\n",
        "    b = np.sqrt(4 * moments['mu11'] ** 2 + (moments['mu20'] - moments['mu02']) ** 2)\n",
        "    ellipticity = np.sqrt((a + b) / (a - b))\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    length = max(w, h)\n",
        "    width = min(w, h)\n",
        "    area = cv2.contourArea(cnt)\n",
        "    perimeter = cv2.arcLength(cnt, True)\n",
        "    diameter = getDiameter(cnt, circularity, rectangularity, ellipticity,area)\n",
        "\n",
        "    apect_ratio = length/width\n",
        "    form_factor = (4*math.pi*area)/perimeter**2\n",
        "    narrow_factor = diameter/length\n",
        "    perimeter_ratio_of_diameter = perimeter/diameter\n",
        "    perimeter_ratio_of_PLW = perimeter/(length+width)\n",
        "\n",
        "    features =np.array([length,width,diameter,area,perimeter,rectangularity,circularity,ellipticity,apect_ratio,form_factor,narrow_factor,perimeter_ratio_of_diameter,perimeter_ratio_of_PLW,texture,3])\n",
        "    return features\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error in getting features\", e)\n",
        "    return None\n",
        "\n",
        "def process_image(image):\n",
        "  # Main\n",
        "  # Load an image\n",
        "  try:\n",
        "    image=resizeImage(image)\n",
        "    filtered_image = applyFilters(image)\n",
        "    flattened_image = flatten(filtered_image)\n",
        "    background_removed = remove_background(flattened_image)\n",
        "    edge = get_edge(background_removed)\n",
        "    cnt = get_contours(edge,image)\n",
        "    features = get_features(cnt)\n",
        "    return features\n",
        "  except Exception as e:\n",
        "    print(\"Error\")"
      ],
      "metadata": {
        "id": "i-EBG5skcWdB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTIONS FOR INPUTTING DATA TO TABLE\n"
      ],
      "metadata": {
        "id": "yffusoXOS3Iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def append_data_to_csv(file_path, data):\n",
        "    try:\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        # Create a new DataFrame with the data to be appended\n",
        "        new_data = pd.DataFrame([data], columns=df.columns)\n",
        "        \n",
        "        # Append the new data to the original DataFrame\n",
        "        df = pd.concat([df, new_data], ignore_index=True)\n",
        "        \n",
        "        # Write the updated data back to the CSV file\n",
        "        df.to_csv(file_path, index=False)\n",
        "        \n",
        "        print(\"Data has been appended to the CSV file successfully!\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred:\", str(e))\n",
        "\n",
        "\n",
        "def read_csv_to_table(file_path):\n",
        "    try:\n",
        "        # Read CSV file into a pandas DataFrame\n",
        "        df = pd.read_csv(file_path)      \n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred:\", str(e))\n",
        "\n",
        "def loop_through_directory(dir_path):\n",
        "    # Loop through all the contents of the directory\n",
        "  for item in os.listdir(dir_path):\n",
        "      # Create the absolute path by joining the directory path and the item name\n",
        "      item_path = os.path.join(dir_path, item)\n",
        "      \n",
        "      # Check if the item is a file\n",
        "      if os.path.isfile(item_path):\n",
        "        image_path = item_path\n",
        "\n",
        "        # Open the image\n",
        "        image = cv2.imread(image_path)\n",
        "        data = np.array(process_image(image))\n",
        "        #append data to csv file\n",
        "        append_data_to_csv(file_path,data)"
      ],
      "metadata": {
        "id": "2ZMEhJE_S2ne"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FUNCTIONS FOR CORRELATION ANALYSIS**"
      ],
      "metadata": {
        "id": "HSIP2-VH60hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_analysis(file_path):\n",
        "  # Load the data into a dataframe\n",
        "  df = pd.read_csv(file_path)  # Replace 'your_data.csv' with your actual data file name\n",
        "\n",
        "  # Perform correlation analysis\n",
        "  corr_matrix = df.corr()  # Compute correlation matrix\n",
        "  sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')  # Create heatmap\n",
        "\n",
        "  # Create scatter plots for each dependent variable against the independent variable\n",
        "  dependent_vars = ['length', 'width', 'diameter', 'area', 'perimeter', 'rectangularity',\n",
        "                    'circularity', 'ellipticity', 'aspect ratio', 'form factor', 'narrow factor',\n",
        "                    'perimeter ratio of diameter', 'perimeter Ratio of Physiological Length and Physiological Width',\n",
        "                    'Texture']\n",
        "  independent_var = 'Species'\n",
        "  for var in dependent_vars:\n",
        "      sns.scatterplot(x=independent_var, y=var, data=df)\n",
        "      plt.xlabel(independent_var)\n",
        "      plt.ylabel(var)\n",
        "      plt.title(f'Scatter plot of {var} vs. {independent_var}')\n",
        "      plt.show()\n",
        "\n",
        "def find_variable_impact(file_path):\n",
        "  \n",
        "  # Load the data into a dataframe\n",
        "  df = pd.read_csv(file_path)  # Replace 'your_data.csv' with your actual data file name\n",
        "\n",
        "  # Prepare the data for regression analysis\n",
        "  X = df[['length', 'width', 'diameter', 'area', 'perimeter', 'rectangularity',\n",
        "                    'circularity', 'ellipticity', 'aspect ratio', 'form factor', 'narrow factor',\n",
        "                    'perimeter ratio of diameter', 'perimeter Ratio of Physiological Length and Physiological Width',\n",
        "                    'Texture']]  # Independent variables\n",
        "  y = df['Species']  # Dependent variable\n",
        "\n",
        "  # Add a constant term to the independent variables\n",
        "  X = sm.add_constant(X)\n",
        "\n",
        "  # Fit the multiple linear regression model\n",
        "  model = sm.OLS(y, X).fit()\n",
        "\n",
        "  # Get the coefficients (impact) of each dependent variable\n",
        "  coefficients = model.params[1:]\n",
        "\n",
        "  # Sort the coefficients by absolute values to identify the variables with the most impact\n",
        "  sorted_coefficients = coefficients.abs().sort_values(ascending=False)\n",
        "\n",
        "  # Print the sorted coefficients\n",
        "  print(\"Dependent variables sorted by impact on the independent variable:\")\n",
        "  print(sorted_coefficients)"
      ],
      "metadata": {
        "id": "zb-I2gZX6x5M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FUNCTION FOR MAIN**"
      ],
      "metadata": {
        "id": "CKc8pXiAlp7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Specify the directory path\n",
        "  dir_path = 'images'\n",
        "  loop_through_directory(dir_path)\n",
        "  read_csv_to_table(file_path)\n",
        "  corr_analysis(file_path)\n",
        "  find_variable_impact(file_path)"
      ],
      "metadata": {
        "id": "QlU-gg80lpWX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "vS4e9WofyHe_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}